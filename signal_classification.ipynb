{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installation of packages","metadata":{}},{"cell_type":"code","source":"pip install gdown -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Download Dataset from google drive","metadata":{}},{"cell_type":"code","source":"!gdown 1V5B7Bt6aJm0UHbR7cRKBEK8jx7lYPVuX","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Importing packages","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport json\nimport random\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.data.Dataset import from_tensor_slices","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import (Input, Conv1D, BatchNormalization, Dropout, Flatten, Dense)\nfrom tensorflow.keras.regularizers import L2\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossEntropy\nfrom tensorflow.keras.metrics import TopKCategoricalAccuracy, AUC, Precision, Recall","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reading Data","metadata":{}},{"cell_type":"code","source":"eeg = pd.read_csv(\"eeg-data.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"unlabeled_eeg = eeg[eeg[\"label\"] == \"unlabeled\"]\neeg = eeg.loc[eeg[\"label\"] != \"unlabeled\"]\neeg = eeg.loc[eeg[\"label\"] != \"everyone paired\"]\n\neeg.drop(\n    [\n        \"indra_time\",\n        \"Unnamed: 0\",\n        \"browser_latency\",\n        \"reading_time\",\n        \"attention_esense\",\n        \"meditation_esense\",\n        \"updatedAt\",\n        \"createdAt\",\n    ],\n    axis=1,\n    inplace=True,\n)\n\neeg.reset_index(drop=True, inplace=True)\neeg.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def convert_string_data_to_values(value_string):\n    str_list = json.loads(value_string)\n    return str_list\n\n\neeg[\"raw_values\"] = eeg[\"raw_values\"].apply(convert_string_data_to_values)\n\nQUALITY_THRESHOLD = 128\n\neeg = eeg.loc[eeg[\"signal_quality\"] < QUALITY_THRESHOLD]\neeg.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Before replacing labels\")\nprint(eeg[\"label\"].unique(), \"\\n\")\nprint(len(eeg[\"label\"].unique()), \"\\n\")\n\n\neeg.replace(\n    {\n        \"label\": {\n            \"blink1\": \"blink\",\n            \"blink2\": \"blink\",\n            \"blink3\": \"blink\",\n            \"blink4\": \"blink\",\n            \"blink5\": \"blink\",\n            \"math1\": \"math\",\n            \"math2\": \"math\",\n            \"math3\": \"math\",\n            \"math4\": \"math\",\n            \"math5\": \"math\",\n            \"math6\": \"math\",\n            \"math7\": \"math\",\n            \"math8\": \"math\",\n            \"math9\": \"math\",\n            \"math10\": \"math\",\n            \"math11\": \"math\",\n            \"math12\": \"math\",\n            \"thinkOfItems-ver1\": \"thinkOfItems\",\n            \"thinkOfItems-ver2\": \"thinkOfItems\",\n            \"video-ver1\": \"video\",\n            \"video-ver2\": \"video\",\n            \"thinkOfItemsInstruction-ver1\": \"thinkOfItemsInstruction\",\n            \"thinkOfItemsInstruction-ver2\": \"thinkOfItemsInstruction\",\n            \"colorRound1-1\": \"colorRound1\",\n            \"colorRound1-2\": \"colorRound1\",\n            \"colorRound1-3\": \"colorRound1\",\n            \"colorRound1-4\": \"colorRound1\",\n            \"colorRound1-5\": \"colorRound1\",\n            \"colorRound1-6\": \"colorRound1\",\n            \"colorRound2-1\": \"colorRound2\",\n            \"colorRound2-2\": \"colorRound2\",\n            \"colorRound2-3\": \"colorRound2\",\n            \"colorRound2-4\": \"colorRound2\",\n            \"colorRound2-5\": \"colorRound2\",\n            \"colorRound2-6\": \"colorRound2\",\n            \"colorRound3-1\": \"colorRound3\",\n            \"colorRound3-2\": \"colorRound3\",\n            \"colorRound3-3\": \"colorRound3\",\n            \"colorRound3-4\": \"colorRound3\",\n            \"colorRound3-5\": \"colorRound3\",\n            \"colorRound3-6\": \"colorRound3\",\n            \"colorRound4-1\": \"colorRound4\",\n            \"colorRound4-2\": \"colorRound4\",\n            \"colorRound4-3\": \"colorRound4\",\n            \"colorRound4-4\": \"colorRound4\",\n            \"colorRound4-5\": \"colorRound4\",\n            \"colorRound4-6\": \"colorRound4\",\n            \"colorRound5-1\": \"colorRound5\",\n            \"colorRound5-2\": \"colorRound5\",\n            \"colorRound5-3\": \"colorRound5\",\n            \"colorRound5-4\": \"colorRound5\",\n            \"colorRound5-5\": \"colorRound5\",\n            \"colorRound5-6\": \"colorRound5\",\n            \"colorInstruction1\": \"colorInstruction\",\n            \"colorInstruction2\": \"colorInstruction\",\n            \"readyRound1\": \"readyRound\",\n            \"readyRound2\": \"readyRound\",\n            \"readyRound3\": \"readyRound\",\n            \"readyRound4\": \"readyRound\",\n            \"readyRound5\": \"readyRound\",\n            \"colorRound1\": \"colorRound\",\n            \"colorRound2\": \"colorRound\",\n            \"colorRound3\": \"colorRound\",\n            \"colorRound4\": \"colorRound\",\n            \"colorRound5\": \"colorRound\",\n        }\n    },\n    inplace=True,\n)\n\nprint(\"After replacing labels\")\nprint(eeg[\"label\"].unique())\nprint(len(eeg[\"label\"].unique()))\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_classes = len(eeg[\"label\"].unique())\nprint(num_classes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualization of data","metadata":{}},{"cell_type":"code","source":"def view_eeg_plot(idx):\n    data = eeg.loc[idx, \"raw_values\"]\n    plt.plot(data)\n    plt.title(f\"Sample random plot\")\n    plt.show()\n\n\nview_eeg_plot(7)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.bar(range(num_classes), eeg[\"label\"].value_counts())\nplt.title(\"Number of samples per class\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()  # Generates a look-up table\nle.fit(eeg[\"label\"])\neeg[\"label\"] = le.transform(eeg[\"label\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = preprocessing.MinMaxScaler()\nseries_list = [\n    scaler.fit_transform(np.asarray(i).reshape(-1, 1)) for i in eeg[\"raw_values\"]\n]\n\nlabels_list = [i for i in eeg[\"label\"]]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = model_selection.train_test_split(\n    series_list, labels_list, test_size=0.15, random_state=42, shuffle=True\n)\n\nprint(\n    f\"Length of x_train : {len(x_train)}\\nLength of x_test : {len(x_test)}\\nLength of y_train : {len(y_train)}\\nLength of y_test : {len(y_test)}\"\n)\n\nx_train = np.asarray(x_train).astype(np.float32).reshape(-1, 512, 1)\ny_train = np.asarray(y_train).astype(np.float32).reshape(-1, 1)\ny_train = to_categorical(y_train)\n\nx_test = np.asarray(x_test).astype(np.float32).reshape(-1, 512, 1)\ny_test = np.asarray(y_test).astype(np.float32).reshape(-1, 1)\ny_test = to_categorical(y_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 64\nSHUFFLE_BUFFER_SIZE = BATCH_SIZE * 2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset =  from_tensor_slices((x_train, y_train))\ntest_dataset =  from_tensor_slices((x_test, y_test))\n\ntrain_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\ntest_dataset = test_dataset.batch(BATCH_SIZE)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vals_dict = {}\nfor i in eeg[\"label\"]:\n    if i in vals_dict.keys():\n        vals_dict[i] += 1\n    else:\n        vals_dict[i] = 1\ntotal = sum(vals_dict.values())\n\n# Formula used - Naive method where\n# weight = 1 - (no. of samples present / total no. of samples)\n# So more the samples, lower the weight\n\nweight_dict = {k: (1 - (v / total)) for k, v in vals_dict.items()}\nprint(weight_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Custom Functions","metadata":{}},{"cell_type":"code","source":"def plot_history_metrics(history: keras.callbacks.History):\n    total_plots = len(history.history)\n    cols = total_plots // 2\n\n    rows = total_plots // cols\n\n    if total_plots % cols != 0:\n        rows += 1\n\n    pos = range(1, total_plots + 1)\n    plt.figure(figsize=(15, 10))\n    for i, (key, value) in enumerate(history.history.items()):\n        plt.subplot(rows, cols, pos[i])\n        plt.plot(range(len(value)), value)\n        plt.title(str(key))\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"def SignalModel():\n\n    inputLayer = Input(shape=(512, 1))\n\n    layer1 = Conv1D(filters=32, kernel_size=3, strides=2, padding=\"same\")(inputLayer)\n    layer1 = BatchNormalization()(layer1)\n\n    layer2 = Conv1D(filters=64, kernel_size=3, strides=2, padding='same', activation='relu')(layer1)\n    layer2 = BatchNormalization()(layer2)\n\n    layer3 = Conv1D(filters=128, kernel_size=5, strides=2, padding='same', activation='relu')(layer1)\n    layer3 = BatchNormalization()(layer3)\n\n    layer4 = Conv1D(filters=256, kernel_size=5, strides=2, padding='same', activation='relu')(layer1)\n    layer4 = BatchNormalization()(layer4)\n\n    layer5 = Conv1D(filters=512, kernel_size=7, strides=2, padding='same', activation='relu')(layer1)\n    layer5 = BatchNormalization()(layer5)\n\n    layer6 = Conv1D(filters=1024, kernel_size=7, strides=2, padding='same', activation='relu')(layer1)\n    layer6 = BatchNormalization()(layer6)\n    layer6 = Dropout(0.2)(layer6)\n\n    layer7 = Flatten()(layer6)\n    layer7 = Dense(units=4096, activation=\"relu\")(layer7)\n    layer7 = Dropout(0.2)(layer7)\n\n    layer8 = Dense(units=2048, activation=\"relu\", kernel_regularizer=L2())(layer7)\n    layer8 = Dropout(0.2)(layer8)\n\n    layer9 = Dense(units=1024, activation=\"relu\", kernel_regularizer=L2())(layer8)\n    layer9 = Dropout(0.2)(layer9)\n\n    layer10 = Dense(units=128, activation=\"relu\", kernel_regularizer=L2())(layer9)\n\n    outputLayer = Dense(units=num_classes, activation=\"softmax\")(layer10)\n\n    return Model(inputs=inputLayer, outputs=outputLayer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = SignalModel()\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"callbacks = [\n    ModelCheckpoint(filepath=\"best_model.keras\", save_best_onpy=True, monitor=\"loss\"),\n    ReduceLROnPlateau(monitor=\"val_top_k_categorical_accuracy\", factor=0.2, patience=2, min_lr=0.000001)\n]\n\noptimizer = Adam(learning_rate=0.001, amsgrad=True)\nloss = CategoricalCrossEntropy()\nmetric = [\n    TopKCategoricalAccuracy(k=3),\n    AUC(),\n    Precision(),\n    Recall()\n]\nepochs = 5","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Compile and Fit","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer=optimizer, loss = loss, metrics = metric)\n\nmodelHistory = model.fit(train_dataset, epochs=epochs, callbacks=callbacks, validation_data=test_dataset, class_weight=weight_dict)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"loss, accuracy, auc, precision, recall = model.evaluate(test_data)\n\nprint(f\"Loss : {loss}\")\nprint(f\"Top 3 Categorical Accuracy : {accuracy}\")\nprint(f\"Area under the Curve (ROC) : {auc}\")\nprint(f\"Precision : {precision}\")\nprint(f\"Recall : {recall}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualization of model","metadata":{}},{"cell_type":"code","source":"plot_history_metrics(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def view_evaluated_eeg_plots(model):\n    start_index = random.randint(10, len(eeg))\n    end_index = start_index + 11\n    data = eeg.loc[start_index:end_index, \"raw_values\"]\n    data_array = [scaler.fit_transform(np.asarray(i).reshape(-1, 1)) for i in data]\n    data_array = [np.asarray(data_array).astype(np.float32).reshape(-1, 512, 1)]\n    original_labels = eeg.loc[start_index:end_index, \"label\"]\n    predicted_labels = np.argmax(model.predict(data_array, verbose=0), axis=1)\n    original_labels = [\n        le.inverse_transform(np.array(label).reshape(-1))[0]\n        for label in original_labels\n    ]\n    predicted_labels = [\n        le.inverse_transform(np.array(label).reshape(-1))[0]\n        for label in predicted_labels\n    ]\n    total_plots = 12\n    cols = total_plots // 3\n    rows = total_plots // cols\n    if total_plots % cols != 0:\n        rows += 1\n    pos = range(1, total_plots + 1)\n    fig = plt.figure(figsize=(20, 10))\n    for i, (plot_data, og_label, pred_label) in enumerate(\n        zip(data, original_labels, predicted_labels)\n    ):\n        plt.subplot(rows, cols, pos[i])\n        plt.plot(plot_data)\n        plt.title(f\"Actual Label : {og_label}\\nPredicted Label : {pred_label}\")\n        fig.subplots_adjust(hspace=0.5)\n    plt.show()\n\n\nview_evaluated_eeg_plots(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}